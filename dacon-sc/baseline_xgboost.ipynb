{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_now_runtime():\n",
    "    import time\n",
    "    now = time.localtime()\n",
    "    return \"%04d-%02d-%02d %02d-%02d-%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 및 데이터\n",
    "### Library & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                         # 데이터 분석 라이브러리\n",
    "import numpy as np                          # 계산 라이브러리\n",
    "from tqdm import tqdm                       # 진행바\n",
    "from sklearn.metrics import roc_auc_score   # AUC 스코어 계산\n",
    "from sklearn.model_selection import KFold   # K-fold CV    \n",
    "from bayes_opt import BayesianOptimization  # 베이지안 최적화 라이브러리  \n",
    "from functools import partial               # 함수 변수 고정\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")           # 경고 문구 미표시\n",
    "model_name = 'xgboost'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = 'data/train.csv'\n",
    "# test_path = 'data/test.csv'\n",
    "model_path = 'model/'+model_name+'_model.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리\n",
    "### Data Cleansing & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 탐색적 자료분석\n",
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 변수 선택 및 모델 구축\n",
    "### Feature Engineering & Initial Modeling\n",
    "\n",
    "1) Feature로 각 플레이어의 종족, 게임 내 이벤트 발생 숫자, 플레이어간 이벤트 발생 숫자의 차이를 사용합니다.\n",
    "1-1) 종족을 숫자로 변환 (T:0, P:1, Z:2)\n",
    "1-2) 이벤트 발생 숫자는 8개 이벤트에 대해 각각 추출\n",
    "1-3) 플레이어간 이벤트 발생 숫자를 Feature로 추가\n",
    "1-4) 플레이어간 이벤트 발생 숫자 차이를 Feature로 추가\n",
    "\n",
    "2) 모델로 XGBClassifier를 사용합니다.\n",
    "\n",
    "3) 훈련 세트를 5등분 하여 5-fold Cross Validation을 수행합니다.\n",
    "\n",
    "4) Bayesian optimization을 사용하여 하이퍼 파라미터를 조정합니다.\n",
    "4-1) 조정되는 하이퍼 파라미터: -\n",
    "4-2) Score로 AUC를 사용하며 AUC가 가장 높도록 하이퍼 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def species_converter(string):\n",
    "    if string == 'T':\n",
    "        return 0\n",
    "    elif string == 'P':\n",
    "        return 1\n",
    "    elif string == 'Z':\n",
    "        return 2\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "def data_preparation(df, answer=False):\n",
    "    game_ids = df['game_id'].unique()\n",
    "    events = ['Ability', 'AddToControlGroup', 'Camera', 'ControlGroup', 'GetControlGroup', 'Right Click', 'Selection', 'SetControlGroup']\n",
    "    unique_event_0, unique_event_1, delta_event = {}, {}, {}\n",
    "    for event in events:\n",
    "        unique_event_0['P0_' + event] = 0\n",
    "        unique_event_1['P1_' + event] = 0\n",
    "        delta_event['delta_' + event] = 0\n",
    "        \n",
    "    species = df.groupby(['game_id', 'player']).species.unique()\n",
    "    event_count = df.groupby(['game_id', 'player']).event.value_counts()\n",
    "    if answer:\n",
    "        winners = df.groupby(['game_id']).winner.max()\n",
    "    \n",
    "    x_data, y_data = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        df_event_count = event_count[game_id].unstack(level=-1)\n",
    "        df = pd.DataFrame(species[game_id])\n",
    "        df = pd.concat([df, df_event_count], axis=1)   \n",
    "        df = df.fillna(0)\n",
    "        \n",
    "        df_P0_species = pd.DataFrame([species_converter(df.loc[0]['species'][0])], columns=['P0_species'])        \n",
    "        df_P1_species = pd.DataFrame([species_converter(df.loc[1]['species'][0])], columns=['P1_species'])\n",
    "        df = df.drop(['species'], axis=1)\n",
    "\n",
    "        df_P0_event = unique_event_0.copy()\n",
    "        for column in df.columns:\n",
    "            df_P0_event['P0_' + column] = df.loc[0][column]\n",
    "        df_P0_event = pd.DataFrame(pd.Series(df_P0_event)).T\n",
    "\n",
    "        df_P1_event = unique_event_1.copy()\n",
    "        for column in df.columns:\n",
    "            df_P1_event['P1_' + column] = df.loc[1][column]\n",
    "        df_P1_event = pd.DataFrame(pd.Series(df_P1_event)).T\n",
    "        \n",
    "        df_delta_event = delta_event.copy()\n",
    "        for column in df.columns:\n",
    "            df_delta_event['delta_' + column] = df_P0_event['P0_' + column][0] - df_P1_event['P1_' + column][0]\n",
    "        df_delta_event = pd.DataFrame(pd.Series(df_delta_event)).T\n",
    "\n",
    "        out = pd.concat([df_P0_species, df_P0_event, df_P1_species, df_P1_event, df_delta_event], axis=1)\n",
    "        out.index = [game_id]\n",
    "        out.index.name = 'game_id'\n",
    "        \n",
    "        x_data.append(out)\n",
    "        if answer:\n",
    "            y_data.append(winners[game_id])  \n",
    "\n",
    "    x_data = pd.concat(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "    \n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.csv 원본 파일 읽고 data_preparation 진행\n",
    "# train = pd.read_csv('data/train.csv')\n",
    "# x_train, y_train = data_preparation(train, answer=True)\n",
    "\n",
    "# 전처리된 데이터 csv 파일로 저장\n",
    "# x_train.to_csv('data/baseline_x_train.csv')\n",
    "# np.savetxt(\"data/baseline_y_train.csv\", y_train, delimiter=\",\")\n",
    "# x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 csv 파일 읽기\n",
    "x_train = pd.read_csv('data/baseline_x_train.csv', index_col='game_id')\n",
    "y_train = np.loadtxt('data/baseline_y_train.csv', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(learning_rate, n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, reg_alpha, reg_lambda, objective='binary:logistic', tree_method='gpu_hist', predictor='cpu_predictor', x_data=None, y_data=None, n_splits=5, output='score'):\n",
    "    score = 0\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(x_data):\n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "        \n",
    "        model = xgb.XGBClassifier(\n",
    "            learning_rate =learning_rate,\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth=int(max_depth),\n",
    "            min_child_weight=min_child_weight,\n",
    "            gamma=gamma,\n",
    "            subsample=np.clip(subsample, 0, 1),\n",
    "            colsample_bytree=np.clip(colsample_bytree, 0, 1),\n",
    "            reg_alpha=reg_alpha,\n",
    "            reg_lambda=reg_lambda,\n",
    "            objective= objective,\n",
    "#             tree_method=tree_method,\n",
    "            predictor=predictor,\n",
    "        )\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        pred = model.predict_proba(x_valid)[:, 1]\n",
    "        true = y_valid\n",
    "        score += roc_auc_score(true, pred)/n_splits\n",
    "    \n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6288  \u001b[0m | \u001b[0m 0.0708  \u001b[0m | \u001b[0m 0.8151  \u001b[0m | \u001b[0m 0.07681 \u001b[0m | \u001b[0m 4.573   \u001b[0m | \u001b[0m 4.386   \u001b[0m | \u001b[0m 1.003e+0\u001b[0m | \u001b[0m 20.31   \u001b[0m | \u001b[0m 37.89   \u001b[0m | \u001b[0m 0.08915 \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6452  \u001b[0m | \u001b[95m 0.3099  \u001b[0m | \u001b[95m 0.6189  \u001b[0m | \u001b[95m 0.04605 \u001b[0m | \u001b[95m 4.437   \u001b[0m | \u001b[95m 5.327   \u001b[0m | \u001b[95m 700.1   \u001b[0m | \u001b[95m 47.52   \u001b[0m | \u001b[95m 14.06   \u001b[0m | \u001b[95m 0.6199  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.639   \u001b[0m | \u001b[0m 0.3833  \u001b[0m | \u001b[0m 0.4004  \u001b[0m | \u001b[0m 0.09427 \u001b[0m | \u001b[0m 5.86    \u001b[0m | \u001b[0m 5.897   \u001b[0m | \u001b[0m 394.5   \u001b[0m | \u001b[0m 17.11   \u001b[0m | \u001b[0m 33.24   \u001b[0m | \u001b[0m 0.04232 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6252  \u001b[0m | \u001b[0m 0.2322  \u001b[0m | \u001b[0m 0.4301  \u001b[0m | \u001b[0m 0.007886\u001b[0m | \u001b[0m 5.533   \u001b[0m | \u001b[0m 5.708   \u001b[0m | \u001b[0m 167.6   \u001b[0m | \u001b[0m 5.057   \u001b[0m | \u001b[0m 13.55   \u001b[0m | \u001b[0m 0.03016 \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.646   \u001b[0m | \u001b[95m 0.8378  \u001b[0m | \u001b[95m 0.5976  \u001b[0m | \u001b[95m 0.09312 \u001b[0m | \u001b[95m 4.991   \u001b[0m | \u001b[95m 4.753   \u001b[0m | \u001b[95m 261.7   \u001b[0m | \u001b[95m 30.09   \u001b[0m | \u001b[95m 16.48   \u001b[0m | \u001b[95m 0.4617  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6258  \u001b[0m | \u001b[0m 0.3517  \u001b[0m | \u001b[0m 0.94    \u001b[0m | \u001b[0m 0.000796\u001b[0m | \u001b[0m 5.947   \u001b[0m | \u001b[0m 5.907   \u001b[0m | \u001b[0m 27.85   \u001b[0m | \u001b[0m 49.33   \u001b[0m | \u001b[0m 49.12   \u001b[0m | \u001b[0m 0.4379  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.6468  \u001b[0m | \u001b[95m 0.863   \u001b[0m | \u001b[95m 0.7555  \u001b[0m | \u001b[95m 0.07703 \u001b[0m | \u001b[95m 4.027   \u001b[0m | \u001b[95m 4.895   \u001b[0m | \u001b[95m 423.4   \u001b[0m | \u001b[95m 48.2    \u001b[0m | \u001b[95m 0.6307  \u001b[0m | \u001b[95m 0.7225  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6443  \u001b[0m | \u001b[0m 0.7333  \u001b[0m | \u001b[0m 0.6774  \u001b[0m | \u001b[0m 0.08752 \u001b[0m | \u001b[0m 4.647   \u001b[0m | \u001b[0m 4.531   \u001b[0m | \u001b[0m 341.9   \u001b[0m | \u001b[0m 49.55   \u001b[0m | \u001b[0m 49.67   \u001b[0m | \u001b[0m 0.3872  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 0.6422  \u001b[0m | \u001b[0m 0.02651 \u001b[0m | \u001b[0m 0.03957 \u001b[0m | \u001b[0m 4.76    \u001b[0m | \u001b[0m 5.371   \u001b[0m | \u001b[0m 869.0   \u001b[0m | \u001b[0m 0.2531  \u001b[0m | \u001b[0m 1.077   \u001b[0m | \u001b[0m 0.3216  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 0.6591  \u001b[0m | \u001b[0m 0.679   \u001b[0m | \u001b[0m 0.0131  \u001b[0m | \u001b[0m 4.813   \u001b[0m | \u001b[0m 4.76    \u001b[0m | \u001b[0m 419.9   \u001b[0m | \u001b[0m 34.05   \u001b[0m | \u001b[0m 20.48   \u001b[0m | \u001b[0m 0.1618  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.646   \u001b[0m | \u001b[0m 0.4078  \u001b[0m | \u001b[0m 0.1244  \u001b[0m | \u001b[0m 0.04057 \u001b[0m | \u001b[0m 5.933   \u001b[0m | \u001b[0m 4.11    \u001b[0m | \u001b[0m 999.0   \u001b[0m | \u001b[0m 47.81   \u001b[0m | \u001b[0m 2.164   \u001b[0m | \u001b[0m 0.4281  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6427  \u001b[0m | \u001b[0m 0.796   \u001b[0m | \u001b[0m 0.4069  \u001b[0m | \u001b[0m 0.02592 \u001b[0m | \u001b[0m 5.548   \u001b[0m | \u001b[0m 5.643   \u001b[0m | \u001b[0m 894.3   \u001b[0m | \u001b[0m 48.99   \u001b[0m | \u001b[0m 48.55   \u001b[0m | \u001b[0m 0.2076  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6454  \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 0.9433  \u001b[0m | \u001b[0m 0.04487 \u001b[0m | \u001b[0m 5.297   \u001b[0m | \u001b[0m 4.673   \u001b[0m | \u001b[0m 814.3   \u001b[0m | \u001b[0m 49.64   \u001b[0m | \u001b[0m 0.7142  \u001b[0m | \u001b[0m 0.3683  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6244  \u001b[0m | \u001b[0m 0.9284  \u001b[0m | \u001b[0m 0.6083  \u001b[0m | \u001b[0m 0.0816  \u001b[0m | \u001b[0m 4.539   \u001b[0m | \u001b[0m 5.086   \u001b[0m | \u001b[0m 22.39   \u001b[0m | \u001b[0m 49.98   \u001b[0m | \u001b[0m 2.002   \u001b[0m | \u001b[0m 0.1267  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.643   \u001b[0m | \u001b[0m 0.7056  \u001b[0m | \u001b[0m 0.4162  \u001b[0m | \u001b[0m 0.01871 \u001b[0m | \u001b[0m 5.69    \u001b[0m | \u001b[0m 5.838   \u001b[0m | \u001b[0m 249.2   \u001b[0m | \u001b[0m 49.7    \u001b[0m | \u001b[0m 5.084   \u001b[0m | \u001b[0m 0.9552  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6307  \u001b[0m | \u001b[0m 0.8574  \u001b[0m | \u001b[0m 0.3192  \u001b[0m | \u001b[0m 0.08325 \u001b[0m | \u001b[0m 4.074   \u001b[0m | \u001b[0m 5.689   \u001b[0m | \u001b[0m 647.8   \u001b[0m | \u001b[0m 1.149   \u001b[0m | \u001b[0m 0.4068  \u001b[0m | \u001b[0m 0.3122  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6344  \u001b[0m | \u001b[0m 0.6037  \u001b[0m | \u001b[0m 0.3212  \u001b[0m | \u001b[0m 0.09846 \u001b[0m | \u001b[0m 4.934   \u001b[0m | \u001b[0m 4.722   \u001b[0m | \u001b[0m 16.18   \u001b[0m | \u001b[0m 2.408   \u001b[0m | \u001b[0m 40.82   \u001b[0m | \u001b[0m 0.3675  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6347  \u001b[0m | \u001b[0m 0.9169  \u001b[0m | \u001b[0m 0.1484  \u001b[0m | \u001b[0m 0.0833  \u001b[0m | \u001b[0m 5.288   \u001b[0m | \u001b[0m 4.19    \u001b[0m | \u001b[0m 317.7   \u001b[0m | \u001b[0m 0.7371  \u001b[0m | \u001b[0m 0.2326  \u001b[0m | \u001b[0m 0.3811  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6386  \u001b[0m | \u001b[0m 0.5299  \u001b[0m | \u001b[0m 0.01729 \u001b[0m | \u001b[0m 0.09408 \u001b[0m | \u001b[0m 5.606   \u001b[0m | \u001b[0m 5.778   \u001b[0m | \u001b[0m 581.0   \u001b[0m | \u001b[0m 49.0    \u001b[0m | \u001b[0m 1.526   \u001b[0m | \u001b[0m 0.1056  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6323  \u001b[0m | \u001b[0m 0.4739  \u001b[0m | \u001b[0m 0.6764  \u001b[0m | \u001b[0m 0.000345\u001b[0m | \u001b[0m 4.891   \u001b[0m | \u001b[0m 5.944   \u001b[0m | \u001b[0m 762.3   \u001b[0m | \u001b[0m 4.437   \u001b[0m | \u001b[0m 47.91   \u001b[0m | \u001b[0m 0.7783  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 0.1248  \u001b[0m | \u001b[0m 0.03924 \u001b[0m | \u001b[0m 0.098   \u001b[0m | \u001b[0m 5.925   \u001b[0m | \u001b[0m 5.249   \u001b[0m | \u001b[0m 264.2   \u001b[0m | \u001b[0m 0.4394  \u001b[0m | \u001b[0m 48.49   \u001b[0m | \u001b[0m 0.2136  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6279  \u001b[0m | \u001b[0m 0.1565  \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 0.05063 \u001b[0m | \u001b[0m 4.373   \u001b[0m | \u001b[0m 5.914   \u001b[0m | \u001b[0m 916.9   \u001b[0m | \u001b[0m 46.57   \u001b[0m | \u001b[0m 0.9434  \u001b[0m | \u001b[0m 0.08101 \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.645   \u001b[0m | \u001b[0m 0.911   \u001b[0m | \u001b[0m 0.07259 \u001b[0m | \u001b[0m 0.05804 \u001b[0m | \u001b[0m 5.082   \u001b[0m | \u001b[0m 5.581   \u001b[0m | \u001b[0m 1.022e+0\u001b[0m | \u001b[0m 47.87   \u001b[0m | \u001b[0m 44.7    \u001b[0m | \u001b[0m 0.4086  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6463  \u001b[0m | \u001b[0m 0.5771  \u001b[0m | \u001b[0m 0.07472 \u001b[0m | \u001b[0m 0.05138 \u001b[0m | \u001b[0m 4.071   \u001b[0m | \u001b[0m 4.158   \u001b[0m | \u001b[0m 995.4   \u001b[0m | \u001b[0m 46.96   \u001b[0m | \u001b[0m 2.421   \u001b[0m | \u001b[0m 0.5391  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6465  \u001b[0m | \u001b[0m 0.362   \u001b[0m | \u001b[0m 0.6965  \u001b[0m | \u001b[0m 0.007112\u001b[0m | \u001b[0m 4.727   \u001b[0m | \u001b[0m 5.753   \u001b[0m | \u001b[0m 1.019e+0\u001b[0m | \u001b[0m 13.21   \u001b[0m | \u001b[0m 3.856   \u001b[0m | \u001b[0m 0.7462  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6223  \u001b[0m | \u001b[0m 0.02448 \u001b[0m | \u001b[0m 0.5908  \u001b[0m | \u001b[0m 0.006763\u001b[0m | \u001b[0m 4.306   \u001b[0m | \u001b[0m 4.227   \u001b[0m | \u001b[0m 1.023e+0\u001b[0m | \u001b[0m 49.1    \u001b[0m | \u001b[0m 4.969   \u001b[0m | \u001b[0m 0.644   \u001b[0m |\n",
      "| \u001b[95m 27      \u001b[0m | \u001b[95m 0.647   \u001b[0m | \u001b[95m 0.5275  \u001b[0m | \u001b[95m 0.7664  \u001b[0m | \u001b[95m 0.05622 \u001b[0m | \u001b[95m 4.273   \u001b[0m | \u001b[95m 5.977   \u001b[0m | \u001b[95m 598.2   \u001b[0m | \u001b[95m 48.88   \u001b[0m | \u001b[95m 49.59   \u001b[0m | \u001b[95m 0.8965  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6406  \u001b[0m | \u001b[0m 0.7706  \u001b[0m | \u001b[0m 0.269   \u001b[0m | \u001b[0m 0.03271 \u001b[0m | \u001b[0m 4.701   \u001b[0m | \u001b[0m 4.462   \u001b[0m | \u001b[0m 142.7   \u001b[0m | \u001b[0m 49.58   \u001b[0m | \u001b[0m 46.73   \u001b[0m | \u001b[0m 0.812   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6452  \u001b[0m | \u001b[0m 0.2845  \u001b[0m | \u001b[0m 0.5702  \u001b[0m | \u001b[0m 0.07224 \u001b[0m | \u001b[0m 4.823   \u001b[0m | \u001b[0m 5.665   \u001b[0m | \u001b[0m 782.3   \u001b[0m | \u001b[0m 49.24   \u001b[0m | \u001b[0m 47.65   \u001b[0m | \u001b[0m 0.4983  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6294  \u001b[0m | \u001b[0m 0.9611  \u001b[0m | \u001b[0m 0.2888  \u001b[0m | \u001b[0m 0.001017\u001b[0m | \u001b[0m 4.564   \u001b[0m | \u001b[0m 5.015   \u001b[0m | \u001b[0m 259.0   \u001b[0m | \u001b[0m 27.49   \u001b[0m | \u001b[0m 18.22   \u001b[0m | \u001b[0m 0.8353  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6408  \u001b[0m | \u001b[0m 0.07979 \u001b[0m | \u001b[0m 0.9051  \u001b[0m | \u001b[0m 0.0979  \u001b[0m | \u001b[0m 5.319   \u001b[0m | \u001b[0m 4.711   \u001b[0m | \u001b[0m 598.5   \u001b[0m | \u001b[0m 45.3    \u001b[0m | \u001b[0m 47.56   \u001b[0m | \u001b[0m 0.8896  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6451  \u001b[0m | \u001b[0m 0.3334  \u001b[0m | \u001b[0m 0.6747  \u001b[0m | \u001b[0m 0.07916 \u001b[0m | \u001b[0m 4.336   \u001b[0m | \u001b[0m 4.45    \u001b[0m | \u001b[0m 100.6   \u001b[0m | \u001b[0m 0.2559  \u001b[0m | \u001b[0m 49.82   \u001b[0m | \u001b[0m 0.5679  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6343  \u001b[0m | \u001b[0m 0.1088  \u001b[0m | \u001b[0m 0.8369  \u001b[0m | \u001b[0m 0.0599  \u001b[0m | \u001b[0m 5.946   \u001b[0m | \u001b[0m 5.136   \u001b[0m | \u001b[0m 498.1   \u001b[0m | \u001b[0m 1.707   \u001b[0m | \u001b[0m 0.8539  \u001b[0m | \u001b[0m 0.4163  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6281  \u001b[0m | \u001b[0m 0.2861  \u001b[0m | \u001b[0m 0.9833  \u001b[0m | \u001b[0m 0.0964  \u001b[0m | \u001b[0m 5.503   \u001b[0m | \u001b[0m 4.095   \u001b[0m | \u001b[0m 92.78   \u001b[0m | \u001b[0m 46.58   \u001b[0m | \u001b[0m 1.541   \u001b[0m | \u001b[0m 0.1062  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6283  \u001b[0m | \u001b[0m 0.7786  \u001b[0m | \u001b[0m 0.2613  \u001b[0m | \u001b[0m 0.08806 \u001b[0m | \u001b[0m 5.935   \u001b[0m | \u001b[0m 5.794   \u001b[0m | \u001b[0m 753.1   \u001b[0m | \u001b[0m 3.528   \u001b[0m | \u001b[0m 0.3686  \u001b[0m | \u001b[0m 0.623   \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "func_fixed = partial(xgb_cv, x_data=x_train, y_data=y_train, predictor='gpu_predictor', n_splits=5, output='score') \n",
    "xgbBO = BayesianOptimization(\n",
    "    func_fixed, \n",
    "    {\n",
    "        'learning_rate' : (0.0001, 0.1),\n",
    "        'n_estimators': (16, 1024),\n",
    "        'max_depth' : (4, 6),\n",
    "        'min_child_weight' : (4, 6),\n",
    "        'gamma' : (0, 1),\n",
    "        'subsample' : (0, 1),\n",
    "        'colsample_bytree' : (0, 1),\n",
    "        'reg_alpha' : (0, 50), \n",
    "        'reg_lambda' : (0, 50),\n",
    "    }, \n",
    "    random_state=4321\n",
    ")\n",
    "xgbBO.maximize(init_points=5, n_iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 학습 및 검증\n",
    "### Model Tuning & Evaluation\n",
    "1) AUC가 가장 높은 하이퍼 파라미터를 사용해 최종 모델을 얻습니다.\n",
    "\n",
    "2) 훈련 세트와 같은 방법으로 테스트 세트에서 Feature를 추출합니다.\n",
    "\n",
    "3) 최종 모델을 사용해 예측을 수행합니다.\n",
    "\n",
    "4) 예측 결과를 submission.csv로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/xgboost_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = xgbBO.max['params']\n",
    "models = xgb_cv(\n",
    "    params['learning_rate'], \n",
    "    params['n_estimators'], \n",
    "    params['max_depth'], \n",
    "    params['min_child_weight'], \n",
    "    params['gamma'], \n",
    "    params['subsample'], \n",
    "    params['colsample_bytree'], \n",
    "    params['reg_alpha'], \n",
    "    params['reg_lambda'], \n",
    "    x_data=x_train, y_data=y_train, n_splits=5, output='model')\n",
    "joblib.dump(models, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.csv 원본 파일 읽고 data_preparation 진행\n",
    "# test = pd.read_csv('data/test.csv')\n",
    "# x_test, _ = data_preparation(test, answer=False)\n",
    "\n",
    "# 전처리된 데이터 csv 파일로 저장\n",
    "# x_test.to_csv('data/baseline_x_test.csv')\n",
    "# x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 csv 파일 읽기\n",
    "x_test = pd.read_csv('data/baseline_x_test.csv', index_col='game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38872</th>\n",
       "      <td>0.615644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38873</th>\n",
       "      <td>0.491244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38874</th>\n",
       "      <td>0.419966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38875</th>\n",
       "      <td>0.304518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38876</th>\n",
       "      <td>0.480850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           winner\n",
       "game_id          \n",
       "38872    0.615644\n",
       "38873    0.491244\n",
       "38874    0.419966\n",
       "38875    0.304518\n",
       "38876    0.480850"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = joblib.load(model_path)\n",
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict_proba(x_test)[:, 1]\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "submission['winner'] = submission['winner'] + pred\n",
    "submission.to_csv(f'submission_{model_name}_{return_now_runtime()}.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 및 결언\n",
    "### Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
