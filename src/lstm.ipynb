{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime, time\n",
    "import multiprocessing\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "import json\n",
    "import logging\n",
    "import logging.config\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib # 모델을 저장하고 불러오는 역할\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import data_loader_v2\n",
    "from utils import data_loader_v3\n",
    "from utils import data_loader_v4\n",
    "from logger.logger import LoggerAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = True\n",
    "model_name = \"lstm\" # RandomForestClassifier, XGBClassifier, lstm\n",
    "epochs = 30\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('./logger/logging.json', 'rt') as f:\n",
    "    config = json.load(f)\n",
    "logging.config.dictConfig(config)\n",
    "logger = logging.getLogger(\"\")\n",
    "logger = LoggerAdapter(\"\", logger)\n",
    "\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = '../data/train_all/'\n",
    "test_folder = '../data/test/'\n",
    "train_label_path = '../data/train_label.csv'\n",
    "model_path = '../model/'+model_name+'_model.pkl'\n",
    "submission_folder = '../submission/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)\n",
    "train_label = pd.read_csv(train_label_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, files, files_num=1, folder='', label=None, event_time=10, nrows=60, sclice=1, rand_row=False):\n",
    "        self.files = files\n",
    "        self.files_num = files_num\n",
    "        self.folder = folder\n",
    "        self.label = label\n",
    "        self.event_time = event_time\n",
    "        self.nrows = nrows\n",
    "        self.sclice = sclice\n",
    "        self.rand_row = rand_row\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.random.randint(len(self.files)) if idx+self.files_num > len(self.files) else idx\n",
    "        func_fixed = partial(\n",
    "            data_loader_v4, \n",
    "            folder=self.folder, \n",
    "            label=self.label, \n",
    "            event_time=self.event_time, \n",
    "            nrows=self.nrows,\n",
    "            sclice=self.sclice,\n",
    "            rand_row=self.rand_row) \n",
    "        if __name__ == '__main__':\n",
    "            pool = Pool(processes=multiprocessing.cpu_count())\n",
    "            if type(self.label) is not type(None):\n",
    "                ts_list = list(pool.imap(func_fixed, self.files[idx:idx+self.files_num]))\n",
    "            else:\n",
    "                ts_list = list(pool.imap(func_fixed, self.files))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            \n",
    "            # multiprocessing 안 쓰고 기본으로 배치 가져올때\n",
    "#         ts_list = data_loader_v4(\n",
    "#             file_name=self.files[idx],\n",
    "#             folder=self.folder, \n",
    "#             label=self.label, \n",
    "#             event_time=self.event_time, \n",
    "#             nrows=self.nrows,\n",
    "#             batch=self.batch)\n",
    "\n",
    "        data_list, label_list = [], []\n",
    "        for d in ts_list:\n",
    "            data_list.append(d[0].to(device)) # .to(device)\n",
    "            label_list.append(d[1].to(device) if d[1] is not None else [-1,]) # .to(device)\n",
    "        data_list = torch.cat(data_list)\n",
    "        label_list = torch.cat(label_list) if label_list[0][0] != -1 else label_list\n",
    "        return data_list, label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MyDataset(\n",
    "    files=train_list, \n",
    "    files_num=10,\n",
    "    folder=train_folder, \n",
    "    label=train_label, \n",
    "    event_time=15, \n",
    "    nrows=600,\n",
    "    sclice=100,\n",
    "    rand_row=True)\n",
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "\n",
    "testset = MyDataset(\n",
    "    files=test_list, \n",
    "    folder=test_folder, \n",
    "    event_time=10, \n",
    "    nrows=60)\n",
    "testloader = DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=5121, hidden_layer_size=768, output_size=198):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        \n",
    "        self.hidden_cell = (Variable(torch.randn(1, 1, hidden_layer_size).to(device)),\n",
    "                            Variable(torch.randn(1, 1, hidden_layer_size).to(device)))\n",
    "#         self.hidden_cell = (Variable(torch.randn(output_size, input_size, hidden_layer_size)),\n",
    "#                             Variable(torch.randn(output_size, input_size, hidden_layer_size)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "#         logger.info(x.size()) # torch.Size([5121])\n",
    "#         logger.info(x.view(1, 1, -1).size()) # torch.Size([1, 1, 5121])\n",
    "#         x, self.hidden_cell = self.lstm(x.view(1, 1, -1), self.hidden_cell) # train\n",
    "        x, self.hidden_cell = self.lstm(x.view(len(x), 1, -1), self.hidden_cell) # test\n",
    "#         logger.info(x.size()) # torch.Size([1, 1, 768])\n",
    "        predictions = self.linear(x.view(len(x), -1))\n",
    "#         logger.info(predictions.size()) # torch.Size([1, 198])\n",
    "#         logger.info(predictions[-1].size()) # torch.Size([198])\n",
    "        return predictions\n",
    "\n",
    "    def inithidden(self):\n",
    "        self.h = Variable(torch.randn(1, 1, 768).to(device))\n",
    "        self.c = Variable(torch.randn(1, 1, 768).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(5121, 768)\n",
      "  (linear): Linear(in_features=768, out_features=198, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "model = model.to(device).float()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# now = datetime.datetime.now()\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     totalloss = 0\n",
    "#     train, label = next(iter(trainloader))\n",
    "# #     logger.info(train.size()) # torch.Size([1, 295, 5121])\n",
    "# #     logger.info(label.size()) # torch.Size([1, 295, 1])\n",
    "#     train = torch.squeeze(train) # torch.Size([295, 5121])\n",
    "#     label = torch.squeeze(label) # torch.Size([295])\n",
    "#     pred_list = []\n",
    "#     for tr, la in zip(train, label):\n",
    "#         optimizer.zero_grad()\n",
    "# #         model.inithidden()\n",
    "#         pred = model(tr)\n",
    "#         pred_list.append(pred)\n",
    "# #         logger.info(pred.size()) # torch.Size([1, 198])\n",
    "# #         loss = loss_function(pred, la)\n",
    "#     pred = torch.cat(pred_list)\n",
    "#     loss = loss_function(pred, label)\n",
    "#     totalloss += loss\n",
    "#     loss.backward(retain_graph=True)\n",
    "#     optimizer.step()\n",
    "\n",
    "#     print(f'epoch: {i:3} loss: {totalloss:10.8f}')\n",
    "\n",
    "# joblib.dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-12 18:40:46,002 - root - INFO - [] torch.Size([500, 1, 5121])\n",
      "2020-02-12 18:40:46,244 - root - INFO - [] torch.Size([500, 198])\n",
      "Wall time: 3.14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jungwoo\\Anaconda3\\envs\\dacon15\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = joblib.load(model_path) \n",
    "test, _ = next(iter(testloader))\n",
    "\n",
    "test = torch.squeeze(test) # torch.Size([295, 5121])\n",
    "pred_list = []\n",
    "# for te in test:\n",
    "optimizer.zero_grad()\n",
    "pred = model(test)\n",
    "pred_list.append(pred)\n",
    "    \n",
    "pred = torch.cat(pred_list)\n",
    "_,ans = torch.max(pred,dim=1)\n",
    "\n",
    "soft = F.softmax(pred)\n",
    "# logger.info(pred.size())\n",
    "# logger.info(pred)\n",
    "# logger.info(ans.size())\n",
    "# logger.info(ans)\n",
    "\n",
    "# \"%%time\n",
    "# model = joblib.load(model_path) \n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# correct = 0\n",
    "# incorrect = 0\n",
    "# rnn.eval()\n",
    "# y_test = []\n",
    "# prediction = []\n",
    "\n",
    "# for batch in test_iter:\n",
    "#     txt = batch.text\n",
    "#     label = batch.label\n",
    "#     y_test.append(label.data[0])\n",
    "\n",
    "#     pred = rnn(txt)\n",
    "#     _,ans = torch.max(pred,dim=1)\n",
    "#     prediction.append(ans.data[0])\n",
    "    \n",
    "#     if ans.data[0] == label.data[0]:\n",
    "#         correct += 1    \n",
    "#     else:\n",
    "#         incorrect += 1\n",
    "    \n",
    "# print ('correct : ', correct)\n",
    "# print ('incorrect : ', incorrect)\n",
    "# print(classification_report(torch.tensor(y_test), \n",
    "#                             torch.tensor(prediction), \n",
    "#                             digits=4, \n",
    "#                             target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = soft.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0003, 0.0002, 0.0029,  ..., 0.0002, 0.0046, 0.0003],\n",
       "        [0.0003, 0.0002, 0.0029,  ..., 0.0002, 0.0046, 0.0003],\n",
       "        [0.0003, 0.0002, 0.0029,  ..., 0.0002, 0.0046, 0.0003],\n",
       "        ...,\n",
       "        [0.0003, 0.0002, 0.0029,  ..., 0.0002, 0.0046, 0.0003],\n",
       "        [0.0003, 0.0002, 0.0029,  ..., 0.0002, 0.0046, 0.0003],\n",
       "        [0.0003, 0.0002, 0.0029,  ..., 0.0002, 0.0046, 0.0003]],\n",
       "       grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=pred)\n",
    "df.to_csv('../test_'+model_name+'.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_now():\n",
    "    now = time.localtime()\n",
    "    return \"%04d-%02d-%02d %02d-%02d-%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=pred)\n",
    "submission.index = test.index\n",
    "submission.index.name = 'id'\n",
    "submission = submission.sort_index()\n",
    "submission = submission.groupby('id').mean()\n",
    "submission.to_csv('../submission_'+model_name+'_'+return_now()+'.csv', index=True) #제출 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('dacon15': conda)",
   "language": "python",
   "name": "python36964bitdacon15conda2b1ac10d1947412984e3b3cde56c3806"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
